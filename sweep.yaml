method: bayes
metric:
  name: epoch/recall_at_1
  goal: maximize

parameters:
  # Narrowed based on best performers (0.0001-0.00025 observed)
  learning_rate:
    distribution: log_uniform_values
    min: 5e-4  # Lower bound from successful runs
    max: 5e-3  # Reduced from 1e-2 to avoid overshooting

  # Adjusted to match best performers' decay patterns
  min_learning_rate:
    distribution: log_uniform_values
    min: 5e-5
    max: 1e-4  # Tighter range based on working configs

  # Focus on stable batch sizes (64/1024 removed)
  batch_size:
    values: [256, 512]  # Top performers used 128-256

  # Reduced to avoid crashes while keeping performance
  hidden_channels:
    values: [256, 512]  # Remove 1024/2048 if causing issues

  # Adjusted based on best gamma range (0.43-0.45)
  circle_loss_gamma:
    values: [256, 512]

  # Narrowed m range from top performers (0.2-0.3 worked best)
  circle_loss_m:
    min: 0.20
    max: 0.60
    distribution: uniform

  # Keep but let early stopping control actual training
  epochs:
    values: [300]

  # Focus on higher patience from successful runs
  early_stopping_patience:
    values: [25]  # Best performers used 45